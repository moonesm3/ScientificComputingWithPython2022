# -*- coding: utf-8 -*-
"""ScientificExe10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KadgKK3i_aCp72-G3JaWhduTpYLqfjeg

# ***Import Simple Essential libraries:***
"""

# Commented out IPython magic to ensure Python compatibility.
import math
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
from scipy import optimize, stats

"""# ***Exe01:***

**Hurricanes per Year**

The number of hurricanes in 2005 was 15. The historic average is 6.3. Is this number signficantly different?

Assume the number of hurricanes is random, i.e. follows the Poisson distribution.
Assume as statistically significant a probability that has a Z score of 3 or larger with respect a normal distribution.
Hint: compute the probability that in a single year are observed 15 or more hurricances.
"""

#Number of hurricanes was 15
#Historic Average = 6.3 = Expected value
#Based on information we have we use Z-test
#Z = xMean − μ / σμ
mu = 6.3
x0 = 15 #Number of hurricanes in 2005
#poisson distribution
from scipy.stats import poisson
n = poisson.rvs(6.3, size = 100 , random_state = 0)
print("Hurricanes happened in 100 years:\n", n )
sigma_mu = math.sqrt(np.mean(n)) #Standard deviation
w = mu - x0

#Z acore measurements
Z = abs(x0 - mu) / sigma_mu
print("Z =", Z)

#P-value measurements
pvalue = stats.norm.cdf(-Z) + (1. - stats.norm.cdf(Z))
print("The pvalue is: " , pvalue)

alpha = 0.05 #Scientific fixing
if (pvalue < alpha):
  print("The null hypothesis is rejected! , " , "pvalue = " , pvalue , "<" , "alpha = " , alpha)
  print("So, in a single year are not observed 15 or more hurricances.")
else:
  print("The null hypothesis is accepted!" "pvalue = " , pvalue , ">" , "alpha = " , alpha)
  print("So, in a single year are not observed 15 or more hurricances.")

#Compute the probability
Probability15Hurricances = 1 - stats.poisson.cdf(k = 14, mu = mu)
print("The probability of 15 hurricances happen is:" , Probability15Hurricances)

"""# ***Exe02:***

**Pairwise t-test**

In an experiment, a group of 10 individuals agreed to participate in a study of blood pressure changes following exposure to halogen lighting. Resting systolic blood pressure was recorded for each individual. The participants were then exposed to 20 minutes in a room lit only by halogen lamps. A post-exposure systolic blood pressure reading was recorded for each individual. The results are presented in the following data set:

```python
pre = np.array([120, 132, 120, 110, 115, 128, 120, 112, 110, 100])
post = np.array([140, 156, 145, 130, 117, 148, 137, 119, 127, 135])
```

Determine whether the change in blood pressures within our sample was statistically significant.

**Hint:**
in this case, the Student's $t$-test should be performed to compare the two datasets.
Use the following test statistics:

$$T = \frac{\bar{x}_1 - \bar{x}_2}{\sigma \sqrt{\frac{2}{n}}}$$

and 

$$\sigma = \sqrt{\frac{\sigma_1^2 + \sigma_2^2}{2}}$$
"""

pre = np.array([120, 132, 120, 110, 115, 128, 120, 112, 110, 100])
post = np.array([140, 156, 145, 130, 117, 148, 137, 119, 127, 135])
FirstMean = mu  = np.mean(pre)  
SecondMean = np.mean(post) 
print("The mean of pre experiment array:" , FirstMean)
print("The mean of post experiment array:" , SecondMean)
FirstSigma = np.sqrt(np.var(pre, ddof = 1))
SecondSigma = np.sqrt(np.var(post, ddof = 1))
TotalSigma = np.sqrt((FirstSigma + SecondSigma) / 2)
print("The sigma of two event is equal to:" , TotalSigma)
T = abs(FirstMean - SecondMean) / TotalSigma * np.sqrt(2 / len(pre))
print("T = " , T)

xs = np.linspace(-10, +10, 1000)
ts = stats.t.pdf(xs, n - 1)
plt.plot(xs, ts)
plt.fill_between(xs, ts, where = np.abs(xs) > np.abs(T), color = "lightblue")
plt.axvline(T, linestyle = "--", color = "r")
plt.axvline(-T, linestyle = "--", color = "b")
plt.show()

#Compute the pvalue
n = len(pre)
pvalue = stats.t.cdf(T, n - 1) + (1. - stats.t.cdf(-T, n - 1))
print("p-value =", pvalue)

alpha = 0.05 #Scientific fixing
if (pvalue < alpha):
  print("The null hypothesis is rejected! , " , "pvalue = " , pvalue , "<" , "alpha = " , alpha)
  print("So, the change in blood pressures within our sample was not statistically significant.")
else:
  print("The null hypothesis is accepted!" "pvalue = " , pvalue , ">" , "alpha = " , alpha)
  print("So, the change in blood pressures within our sample was statistically significant.")

"""# ***Exe03:***

**Curve fitting of temperature in Alaska** 

The temperature extremes in Alaska for each month, starting in January, are given by (in degrees Celcius):

max:  `17,  19,  21,  28,  33,  38, 37,  37,  31,  23,  19,  18`

min: `-62, -59, -56, -46, -32, -18, -9, -13, -25, -46, -52, -58`

* Plot these temperatures.
* Find a suitable a function that can describe min and max temperatures. 
* Fit this function to the data with `scipy.optimize.curve_fit()`.
* Plot the result. Is the fit reasonable? If not, why?
* Is the time offset for min and max temperatures the same within the fit accuracy?
"""

max = [17, 19, 21, 28, 33, 38, 37, 37, 31, 23, 19, 18]
min = [-62, -59, -56, -46, -32, -18, -9, -13, -25, -46, -52, -58]
#Plotting these temperatures
months = np.arange(12)
plt.plot(months, max ,"k")
plt.plot(months, min , "c")
plt.xlabel("Months")
plt.ylabel("Min and max temperature")

#Choose function to fit 
import math
import scipy
def Guess(Range,temperature, x0, sigma,o): 
        return (o + o/0.004) + temperature * np.exp(-(2 * Range - x0) ** 2 / (2 * math.pow(sigma , 2)))

PerMonth = np.arange(0,len(months))
Colors = np.array([0, 10, 20, 30, 40, 45, 50, 55, 60, 70, 80, 90])
plt.scatter(PerMonth , max, c = Colors, cmap = "viridis")
plt.scatter(PerMonth , min , c = Colors, cmap = "viridis")
MaxMax ,_ = scipy.optimize.curve_fit(Guess , PerMonth , max)
MinMin,_ = scipy.optimize.curve_fit(Guess , PerMonth , min)
print("Optimized parameters per max:" , MaxMax)
print("Optimized parameters per min:" , MinMin)
x = np.linspace(0 , 12 , 100)
yPerMax = Guess(x , MaxMax[0] , MaxMax[1] , MaxMax[2] , MaxMax[3])
yPerMin = Guess(x , MinMin[0] , MinMin[1] , MinMin[2] , MinMin[3])
plt.plot(x , yPerMax , color = "k")
plt.plot(x , yPerMin , color = "k")

"""The fit is reasonable based on information we have.

# ***Exe04:***

**Fit the residues**

Read the `data/residuals_261.pkl` file. If you haven't got it already, download it from here:

```bash
wget https://www.dropbox.com/s/3uqleyc3wyz52tr/residuals_261.pkl -P data/
```

The feature named `residual` contains the residuals (defined as $y_i - \hat{y}_i$) of a linear regression as a function of the independent variable `distances`.

- Considering only the "residual" feature, create an histogram with the appropriate binning and plot it.
- Set the appropriate Poisson uncertainty for each bin (thus, for each bin, $\sigma_i = \sqrt{n_i}$, where $n_i$ is the number of entries in each bin)
- By looking at the distribution of the residuals, define an appropriate function and fit it to the histogram of the residuals
- Perform a goodness-of-fit test. Is the p-value of the fit satisfactory?
"""

!wget https://www.dropbox.com/s/3uqleyc3wyz52tr/residuals_261.pkl -P data/

df = pd.read_pickle("data/residuals_261.pkl")
df = pd.DataFrame(df.item())
df

Residuals = df["residuals"]
Distances = df["distances"]
residuals = Residuals.to_numpy()
distances = Distances.to_numpy()

#Histogram
fig,ax1 = plt.subplots(figsize = (10,10))
height,bins,_ = ax1.hist(residuals, bins = 150, range = (-10 , 6) , color = "c")
bin_center = (bins[:-1] + bins[1:]) / 2
sigma = np.sqrt(abs(height))
ax1.errorbar(x = bin_center , y = height , yerr = sigma , color = "k" , linestyle = "--")

#Define functiona and fit it
def Guess2(x, amp, cen, wid, offset):
         return amp * np.exp(-(x-cen)**2 / (2*wid**2)) + offset
from scipy.optimize import curve_fit
params, cov = curve_fit(Guess2, bin_center , len(residuals))
mu, std = stats.norm.fit(residuals)
InitialPoint = [np.amax(residuals) , mu , std , 0]
print("Mean and standard deviation are: " , mu,std)
offset = InitialPoint
GuessFit = Guess2(bin_center, *params)
plt.plot(bin_center, Guess2(bin_center, *params) , color = "k")
print(GuessFit)

#Goodness of the fit
import scipy
value = tuple(params)
chi2 = np.sum(((height - GuessFit) ** 2) / std ** 2)
print("chi2 = " , chi2)
pvalue = 1. - scipy.stats.chi2.cdf(chi2 , len(bin_center) - 1 )
print("pvalue = ",pvalue)
ndof = len(value) - 1 #Degree of freedom

"""# ***Exe05:***

**Temperatures in Munich**

Get the following data file:

```bash
https://www.dropbox.com/s/7gy9yjl00ymxb8h/munich_temperatures_average_with_bad_data.txt
```

which gives the temperature in Munich every day for several years.


Fit the following function to the data:

$$f(t) = a \cos(2\pi t + b)+c$$

where $t$ is the time in years.

- Make a plot of the data and the best-fit model in the range 2008 to 2012.

   - What are the best-fit values of the parameters?

   - What is the overall average temperature in Munich, and what are the typical daily average values predicted by the model for the coldest and hottest time of year?

   - What is the meaning of the $b$ parameter, and what physical sense does it have?


- Now fit the data with the function $g(x)$, which has 1 more parameter than $f(x)$.
$$g(x) = a \cos(2\pi b t + c)+d$$
   - What are the RSS for $f(x)$ and $g(x)$?
   - Use the Fisher F-test to determine whether the additional parameter is motivated.
"""

!wget https://www.dropbox.com/s/7gy9yjl00ymxb8h/munich_temperatures_average_with_bad_data.txt

#Reading the datas
columns = ["Dates" , "Temperatures"] 
df = pd.read_csv("munich_temperatures_average_with_bad_data.txt" , sep = "\s+")
df.columns = ["Year", "Temperature"]
df

def Function(t,a,b,c):    #g(x) = a * cos(2* pi * t + b) + c
    return a * np.cos(2 * np.pi * t + b) + c   # t is time in the years

#Get data in range 2008 to 2012
Newdf = df[(df["Year"] > 2008) & (df["Year"] < 2012)].reset_index()
Newdf = Newdf.drop(["index"] , axis = 1)
Newdf

#Plot the data
plt.plot(Newdf["Year"], Newdf["Temperature"], color = "k")